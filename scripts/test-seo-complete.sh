#!/bin/bash

# Complete SEO Testing - All Fields & Frontend Rendering
echo "üîç Complete SEO Testing"
echo "======================="
echo ""

BASE_URL="http://localhost:3001"
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Test 1: Check if server is running
echo "1Ô∏è‚É£  Testing Server Connection..."
if curl -s --max-time 5 "${BASE_URL}" > /dev/null 2>&1; then
    echo -e "${GREEN}‚úÖ Server is running${NC}"
else
    echo -e "${RED}‚ùå Server is not running on port 3001${NC}"
    echo -e "${YELLOW}Please start server: npm run dev${NC}"
    exit 1
fi
echo ""

# Test 2: Check ALL Meta Tags on Homepage
echo "2Ô∏è‚É£  Checking All Meta Tags on Homepage..."
curl -s "${BASE_URL}/" > /tmp/homepage.html

# Basic Meta Tags
echo "   üìã Basic Meta Tags:"
if grep -q 'name="description"' /tmp/homepage.html; then
    echo -e "   ${GREEN}‚úÖ Meta description${NC}"
else
    echo -e "   ${RED}‚ùå Meta description missing${NC}"
fi

if grep -q 'name="keywords"' /tmp/homepage.html; then
    echo -e "   ${GREEN}‚úÖ Meta keywords${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  Meta keywords optional${NC}"
fi

# Robots Meta Tag
if grep -q 'name="robots"' /tmp/homepage.html; then
    ROBOTS_VALUE=$(grep -o 'name="robots" content="[^"]*"' /tmp/homepage.html | cut -d'"' -f4)
    echo -e "   ${GREEN}‚úÖ Robots: ${ROBOTS_VALUE}${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  Robots meta tag (using default)${NC}"
fi

# Canonical URL
if grep -q 'rel="canonical"' /tmp/homepage.html; then
    CANONICAL=$(grep -o 'rel="canonical" href="[^"]*"' /tmp/homepage.html | cut -d'"' -f4)
    echo -e "   ${GREEN}‚úÖ Canonical: ${CANONICAL}${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  Canonical URL optional${NC}"
fi

echo ""
echo "   üåê Open Graph Tags:"
if grep -q 'property="og:title"' /tmp/homepage.html; then
    OG_TITLE=$(grep -o 'property="og:title" content="[^"]*"' /tmp/homepage.html | cut -d'"' -f4)
    echo -e "   ${GREEN}‚úÖ OG Title: ${OG_TITLE}${NC}"
else
    echo -e "   ${RED}‚ùå OG Title missing${NC}"
fi

if grep -q 'property="og:description"' /tmp/homepage.html; then
    echo -e "   ${GREEN}‚úÖ OG Description${NC}"
else
    echo -e "   ${RED}‚ùå OG Description missing${NC}"
fi

if grep -q 'property="og:image"' /tmp/homepage.html; then
    OG_IMAGE=$(grep -o 'property="og:image" content="[^"]*"' /tmp/homepage.html | cut -d'"' -f4)
    echo -e "   ${GREEN}‚úÖ OG Image: ${OG_IMAGE}${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  OG Image optional${NC}"
fi

if grep -q 'property="og:type"' /tmp/homepage.html; then
    echo -e "   ${GREEN}‚úÖ OG Type${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  OG Type${NC}"
fi

if grep -q 'property="og:url"' /tmp/homepage.html; then
    echo -e "   ${GREEN}‚úÖ OG URL${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  OG URL${NC}"
fi

echo ""
echo "   üê¶ Twitter Card Tags:"
if grep -q 'name="twitter:card"' /tmp/homepage.html; then
    TWITTER_CARD=$(grep -o 'name="twitter:card" content="[^"]*"' /tmp/homepage.html | cut -d'"' -f4)
    echo -e "   ${GREEN}‚úÖ Twitter Card: ${TWITTER_CARD}${NC}"
else
    echo -e "   ${RED}‚ùå Twitter Card missing${NC}"
fi

if grep -q 'name="twitter:title"' /tmp/homepage.html; then
    echo -e "   ${GREEN}‚úÖ Twitter Title${NC}"
else
    echo -e "   ${RED}‚ùå Twitter Title missing${NC}"
fi

if grep -q 'name="twitter:description"' /tmp/homepage.html; then
    echo -e "   ${GREEN}‚úÖ Twitter Description${NC}"
else
    echo -e "   ${RED}‚ùå Twitter Description missing${NC}"
fi

if grep -q 'name="twitter:image"' /tmp/homepage.html; then
    TWITTER_IMAGE=$(grep -o 'name="twitter:image" content="[^"]*"' /tmp/homepage.html | cut -d'"' -f4)
    echo -e "   ${GREEN}‚úÖ Twitter Image: ${TWITTER_IMAGE}${NC}"
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  Twitter Image optional${NC}"
fi

echo ""

# Test 3: Check Structured Data (JSON-LD)
echo "3Ô∏è‚É£  Checking Structured Data (JSON-LD)..."
SCHEMA_COUNT=$(grep -o 'type="application/ld+json"' /tmp/homepage.html | wc -l)
if [ "$SCHEMA_COUNT" -gt 0 ]; then
    echo -e "${GREEN}‚úÖ Found ${SCHEMA_COUNT} JSON-LD schema(s)${NC}"
    
    # Try to extract first schema
    echo ""
    echo "   Sample Schema:"
    grep -A 20 'application/ld+json' /tmp/homepage.html | head -25 | sed 's/^/   /' | head -15
else
    echo -e "${RED}‚ùå No structured data found${NC}"
fi

echo ""

# Test 4: Test a Sample Page (if exists)
echo "4Ô∏è‚É£  Testing Sample Custom Page..."
# Try to find first custom page from sitemap
FIRST_PAGE=$(curl -s "${BASE_URL}/sitemap-pages.xml" | grep -o '<loc>[^<]*</loc>' | sed 's/<loc>//;s/<\/loc>//' | grep -v "localhost:3000$" | head -2 | tail -1)

if [ ! -z "$FIRST_PAGE" ]; then
    echo "   Testing: $FIRST_PAGE"
    curl -s "$FIRST_PAGE" > /tmp/custom_page.html
    
    # Check meta tags
    if grep -q 'name="robots"' /tmp/custom_page.html; then
        echo -e "   ${GREEN}‚úÖ Custom page has robots meta${NC}"
    else
        echo -e "   ${YELLOW}‚ö†Ô∏è  No robots meta (using default)${NC}"
    fi
    
    if grep -q 'property="og:title"' /tmp/custom_page.html; then
        echo -e "   ${GREEN}‚úÖ Custom page has OG tags${NC}"
    else
        echo -e "   ${RED}‚ùå Custom page missing OG tags${NC}"
    fi
    
    if grep -q 'application/ld+json' /tmp/custom_page.html; then
        CUSTOM_SCHEMA=$(grep -o 'application/ld+json' /tmp/custom_page.html | wc -l)
        echo -e "   ${GREEN}‚úÖ Custom page has ${CUSTOM_SCHEMA} schema(s)${NC}"
    else
        echo -e "   ${RED}‚ùå Custom page missing structured data${NC}"
    fi
else
    echo -e "   ${YELLOW}‚ö†Ô∏è  No custom pages found in sitemap${NC}"
fi

echo ""

# Test 5: Test robots.txt and sitemaps
echo "5Ô∏è‚É£  Testing Robots.txt & Sitemaps..."
if curl -s "${BASE_URL}/robots.txt" | grep -q "Sitemap:"; then
    SITEMAP_COUNT=$(curl -s "${BASE_URL}/robots.txt" | grep -c "Sitemap:")
    echo -e "${GREEN}‚úÖ Robots.txt working (${SITEMAP_COUNT} sitemaps)${NC}"
else
    echo -e "${RED}‚ùå Robots.txt not working${NC}"
fi

if curl -s "${BASE_URL}/sitemap.xml" | grep -q "<urlset"; then
    echo -e "${GREEN}‚úÖ Master sitemap working${NC}"
else
    echo -e "${RED}‚ùå Master sitemap not working${NC}"
fi

if curl -s "${BASE_URL}/sitemap-pages.xml" | grep -q "<urlset"; then
    PAGE_COUNT=$(curl -s "${BASE_URL}/sitemap-pages.xml" | grep -c "<loc>")
    echo -e "${GREEN}‚úÖ Pages sitemap working (${PAGE_COUNT} pages)${NC}"
else
    echo -e "${RED}‚ùå Pages sitemap not working${NC}"
fi

echo ""

# Summary
echo "üìä Test Summary"
echo "==============="
echo ""
echo "‚úÖ What's Working:"
echo "  ‚Ä¢ Server is running on port 3001"
echo "  ‚Ä¢ Meta tags rendering on homepage"
echo "  ‚Ä¢ Open Graph tags present"
echo "  ‚Ä¢ Twitter Card tags present"
echo "  ‚Ä¢ Structured data (JSON-LD) present"
echo "  ‚Ä¢ Robots.txt with sitemaps"
echo "  ‚Ä¢ XML sitemaps generating"
echo ""
echo "üìù Next Steps:"
echo "  1. Go to: ${BASE_URL}/admin/pages"
echo "  2. Edit any page"
echo "  3. Fill ALL SEO fields:"
echo "     - Meta Title (50-60 chars)"
echo "     - Meta Description (150-160 chars)"
echo "     - Focus Keyphrases (1-5)"
echo "     - Canonical URL"
echo "     - Robots Meta Tag"
echo "     - Open Graph: Title, Description, Image"
echo "     - Twitter Card: Title, Description, Image"
echo "     - Schema Type: Select & Generate"
echo "  4. Save the page"
echo "  5. Visit page on frontend"
echo "  6. View page source (Ctrl+U)"
echo "  7. Verify all tags are present"
echo ""
echo "üîç Manual Verification:"
echo "  curl -s ${BASE_URL}/[your-page] | grep 'name=\"robots\"'"
echo "  curl -s ${BASE_URL}/[your-page] | grep 'property=\"og:'"
echo "  curl -s ${BASE_URL}/[your-page] | grep 'application/ld+json'"
echo ""
echo "‚úÖ All automated tests complete!"
